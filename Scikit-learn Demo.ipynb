{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Scikit-Learn for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn is a python library for machine learning. Some things you can do with [scikit-learn](http://scikit-learn.org/stable/)\n",
    "<img src=\"scikit-learn.png\" width=\"800\">\n",
    "\n",
    "In this demo we'll see:\n",
    "1. How to load data from different sources.\n",
    "1. How to do apply some data preprocessing using [scikit-learn](http://scikit-learn.org/stable/) and [Pandas](https://pandas.pydata.org/), which is a collection of python tools for data analysis.\n",
    "2. How to use scikit-learn for cross-validation\n",
    "2. How to run all the algorithms we've seen in class (decision tree, perceptron, SVM) with scikit-learn\n",
    "\n",
    "\n",
    "*Note*: The tutorials here are not an exhaustive representation of what we can do with these tools. They are meant to give you an starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Installed Datsets\n",
    "\n",
    "Scikit learn has some [pre-installed datasets](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets). We're going to check out the Iris dataset. More information on the dataset is available here: \n",
    "1. [UCI Machine learning Repository](https://archive.ics.uci.edu/ml/datasets/iris)\n",
    "2. [Wikipedia article about the dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set)\n",
    "\n",
    "Let us first load the dataset. (To run the any of the code cells, you click on it and press Shift+Enter.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us quickly see what the dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])\n",
      "Number of samples: 150\n",
      "Number of features: 4\n",
      "Features: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "[ 5.1  3.5  1.4  0.2]\n"
     ]
    }
   ],
   "source": [
    "print(iris.keys())\n",
    "#You can check out the description of the dataset using the following command\n",
    "#print(iris.DESCR)\n",
    "\n",
    "n_samples, n_features = iris.data.shape\n",
    "print('Number of samples:', n_samples)\n",
    "print('Number of features:', n_features)\n",
    "# the sepal length, sepal width, petal length and petal width of the first sample (first flower)\n",
    "print('Features:', iris.feature_names)\n",
    "print(iris.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the features: (150, 4)\n",
      "Shape of the labels: (150,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the features:\", iris.data.shape)\n",
    "print(\"Shape of the labels:\", iris.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# all of the labels\n",
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a scatter plot of the data to get an idea of how it looks. For this we'll use python library, Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e4909e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# A scatter plot of the 3rd feature against the 0th feature.\n",
    "x_index = 3\n",
    "y_index = 0\n",
    "\n",
    "colors = ['blue', 'red', 'green']\n",
    "\n",
    "for label, color in zip(range(len(iris.target_names)), colors):\n",
    "    plt.scatter(iris.data[iris.target==label, x_index], \n",
    "                iris.data[iris.target==label, y_index],\n",
    "                label=iris.target_names[label],\n",
    "                c=color)\n",
    "\n",
    "plt.xlabel(iris.feature_names[x_index])\n",
    "plt.ylabel(iris.feature_names[y_index])\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading your own dataset\n",
    "\n",
    "There are different places where you can find data sets like Kaggle, [the UCI repository](https://archive.ics.uci.edu/ml/datasets.html), etc.\n",
    "\n",
    "Here, we'll be using the Titanic Passenger Survival Data Set. The description can be found here: https://www.kaggle.com/c/titanic/data. Briefly, the goal is to predict whether a passenger survived the Titanic disaster or not.\n",
    "\n",
    "We have already included the dataset in this git repository in the file `titanic.csv`. Let us load it from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in titanic.csv: ['pclass', 'survived', 'name', 'sex', 'age', 'sibsp', 'parch', 'ticket', 'fare', 'cabin', 'embarked', 'boat', 'body', 'home.dest']\n",
      "Data shape (rows, columns) =   (1309, 5)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#loading the datset from .csv file\n",
    "titanic = pd.read_csv(os.path.join('data', 'titanic.csv'))\n",
    "\n",
    "#print columns in the table\n",
    "print(\"Columns in titanic.csv: \" + str(list(titanic.columns)))\n",
    "\n",
    "#labels are stored in column named 'survived'. Let us save it in a variable called labels.\n",
    "labels = titanic.survived.values\n",
    "\n",
    "#fetch the columns that we'll be using for our models\n",
    "data = titanic[['pclass', 'sex', 'sibsp', 'parch', 'embarked']]\n",
    "print(\"Data shape (rows, columns) =  \", data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start with the machine learning, let's see the survival rate based on the gender of the passenger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    682\n",
      "1    161\n",
      "Name: survived, dtype: int64\n",
      "0    127\n",
      "1    339\n",
      "Name: survived, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x10b478ef0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAE/CAYAAAB1vdadAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1a373198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, split the data by male/female.\n",
    "df_male = titanic.survived[titanic.sex == 'male'].value_counts().sort_index()\n",
    "df_female = titanic.survived[titanic.sex == 'female'].value_counts().sort_index()\n",
    "\n",
    "print(df_male)\n",
    "print(df_female)\n",
    "\n",
    "# Use matplotlib again for plotting \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "label_values = [0,1]\n",
    "plt.bar([l - 0.15 for l in label_values], df_male, 0.3, label = 'Male', alpha=0.55)\n",
    "plt.bar([l + 0.15 for l in label_values], df_female, 0.3,color='#FA2379', label = 'Female', alpha=0.55)\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_xticklabels(['Not survived', 'Survived'])\n",
    "plt.title(\"Who Survived? with respect to Gender, (raw value counts) \"); plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Scikit-learn with real world data: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at some techniques for transforming the features now.\n",
    "\n",
    "### Binning\n",
    "Binning is a technique which is used to convert continuous values to discrete values for the ease of classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "0    29.0000\n",
      "1     0.9167\n",
      "2     2.0000\n",
      "3    30.0000\n",
      "4    25.0000\n",
      "Name: age, dtype: float64\n",
      "\n",
      "fare\n",
      "0    211.3375\n",
      "1    151.5500\n",
      "2    151.5500\n",
      "3    151.5500\n",
      "4    151.5500\n",
      "Name: fare, dtype: float64\n",
      "\n",
      "property | Age | Fare\n",
      "min 0.1667 0.0\n",
      "max 80.0 512.3292\n",
      "median 28.0 14.4542\n",
      "mean 29.8811345124 33.2954792813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1309, 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's have a look at ages and fares\n",
    "print('age')\n",
    "print(titanic['age'].head(5))\n",
    "print()\n",
    "print('fare')\n",
    "print(titanic['fare'].head(5))\n",
    "print()\n",
    "\n",
    "#lets look at min, max, median and mean for age and fare. This will help us in deciding the bins\n",
    "print('property | Age | Fare')\n",
    "print('min', titanic['age'].min(), titanic['fare'].min())\n",
    "print('max', titanic['age'].max(), titanic['fare'].max())\n",
    "print('median', titanic['age'].median(), titanic['fare'].median())\n",
    "print('mean', titanic['age'].mean(), titanic['fare'].mean())\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>embarked</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>adult</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>young</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>young</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>adult</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>young</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass     sex  sibsp  parch embarked    age  fare\n",
       "0       1  female      0      0        S  adult  high\n",
       "1       1    male      1      2        S  young  high\n",
       "2       1  female      1      2        S  young  high\n",
       "3       1    male      1      2        S  adult  high\n",
       "4       1  female      1      2        S  young  high"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create bins for age and fare\n",
    "bins_age = [0, 25, 60,  100]\n",
    "bins_fare = [0, 25, 100, 1000]\n",
    "\n",
    "age_groups = ['young', 'adult', 'senior']\n",
    "fare_groups = ['low', 'medium', 'high']\n",
    "\n",
    "data.loc[:, 'age'] = pd.cut(titanic.loc[:, 'age'], bins_age, labels=age_groups)\n",
    "data.loc[:, 'fare'] = pd.cut(titanic.loc[:, 'fare'], bins_fare, labels=fare_groups)\n",
    "\n",
    "#remove original columns\n",
    "# del data['age']\n",
    "# del data['fare']\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Categorical values to Numerical values\n",
    "\n",
    "Here we will be converting categorical values like Male/Female to numerical values like 1/2 for easier processing.\n",
    "\n",
    "Here, we'll be using 2 different techniques:\n",
    "- LabelEncoder: This is used when none of the values for this column are missing.\n",
    "- factorize: This is used when there are missing values. The missing value is assigned the value of -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pclass  sex  sibsp  parch  embarked  age  fare\n",
      "0       1    0      0      0         0    0     0\n",
      "1       1    1      1      2         0    1     0\n",
      "2       1    0      1      2         0    1     0\n",
      "3       1    1      1      2         0    0     0\n",
      "4       1    0      1      2         0    1     0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>embarked</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  sex  sibsp  parch  embarked  age  fare\n",
       "0       1    0      0      0         0    0     0\n",
       "1       1    1      1      2         0    1     0\n",
       "2       1    0      1      2         0    1     0\n",
       "3       1    1      1      2         0    0     0\n",
       "4       1    0      1      2         0    1     0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "#let's check the values before we change categorical values to numbers.\n",
    "print(data.head(5))\n",
    "\n",
    "le = LabelEncoder()\n",
    "data['sex'] = le.fit_transform(data['sex'])\n",
    "\n",
    "#select only those columns that are categorical\n",
    "for column in data.select_dtypes(include=['object', 'category']).columns:\n",
    "    data[column] = data[column].factorize()[0]\n",
    "\n",
    "#after processing\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing values\n",
    "\n",
    "There are different ways to handle missing values. Here we're using `fillna()` from pandas since we had categorical values. You could also use `Imputer` from scikit-learn to fill with mean, median etc. See [the documentation](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Imputer.html) to learn more about it.\n",
    "\n",
    "In either case, we need to replace -1 with `np.nan` (i.e. not-a-number). This is needed because `factorize()` from above encodes missing values as -1.\n",
    "\n",
    "Not that, `Imputer` returns an `ndarray1`, whereas `fillna` gives us a `dataframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>embarked</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  sex  sibsp  parch  embarked  age  fare\n",
       "0       1    0      0      0       0.0    0     0\n",
       "1       1    1      1      2       0.0    1     0\n",
       "2       1    0      1      2       0.0    1     0\n",
       "3       1    1      1      2       0.0    0     0\n",
       "4       1    0      1      2       0.0    1     0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "import numpy as np \n",
    "\n",
    "data = data.replace(-1, np.nan)\n",
    "\n",
    "#try this\n",
    "# imp = Imputer(strategy=\"median\") # can supply different strategies\n",
    "# imp.fit(data)\n",
    "# data = imp.transform(data)\n",
    "\n",
    "data = data.fillna(data.median()) # can try with sum, mean etc.\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Categorical Values to Boolean Values (Binary Values)\n",
    "We will be using one-hot-encoding to convert categorical features to binary features.\n",
    "\n",
    "#### What is one-hot-encoding?\n",
    "\n",
    "When a column has categorical values, it is hard for the machine learning algorithm to train  upon. To make it more suitable for the ML algorithms, we convert each category for that column to a boolean column. Only one of the columns can take a value of one for a single sample. Hence, it is called as one hot encoding. \n",
    "\n",
    "(eg) Suppose you have ‘flower’ feature which can take values ‘daffodil’, ‘lily’, and ‘rose’. One hot encoding converts ‘flower’ feature to three features, ‘is_daffodil’, ‘is_lily’, and ‘is_rose’ which all are binary.\n",
    "\n",
    "We will be using pandas' get_dummies() function which is equivalent to scikit-learn [OneHotEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder).\n",
    "\n",
    "Refer: https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns: 31\n",
      "rows: 1309\n",
      "[ 1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# to convert all categorical columns to boolean columns\n",
    "# data = pd.get_dummies(data)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc_data = enc.fit_transform(data).toarray()\n",
    "\n",
    "# you can also select the columns to convert. I don't know why you would do that though!\n",
    "# data = pd.get_dummies(data, columns=[ 'sex', 'embarked', 'age', 'fare'])\n",
    "print('columns:', enc_data.shape[1])\n",
    "print('rows:', enc_data.shape[0])\n",
    "\n",
    "print(enc_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the original age data is 0.991596638655\n",
      "The std  of the original age data is 1.12481991866\n",
      "\n",
      "The mean of the transformed age data is -8.68501434084e-17\n",
      "The std  of the transformed age data is 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "processed_age_data = preprocessing.scale(data['age'])\n",
    "\n",
    "print(\"The mean of the original age data is\", data['age'].mean(axis=0))\n",
    "print(\"The std  of the original age data is\", data['age'].std(axis=0))\n",
    "print()\n",
    "\n",
    "print(\"The mean of the transformed age data is\", processed_age_data.mean(axis=0))\n",
    "print(\"The std  of the transformed age data is\", processed_age_data.std(axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Test-Train Split\n",
    "Here we'll create train and test splits to train and test our algorithm.\n",
    "\n",
    "We'll keep two sets: \n",
    "1. without OneHotEncoding (we will call this setting A) and \n",
    "2. with OneHotEncoding (setting B).\n",
    "\n",
    "We will compare the results of the two for each algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits without encoded values. We will call this setting 'A'\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, random_state=0)\n",
    "\n",
    "# splits with encoded values. We will call this setting 'B'\n",
    "enc_train_data, enc_test_data, enc_train_labels, enc_test_labels = train_test_split(enc_data, labels, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly predicting a label\n",
    "\n",
    "Here we'll see a classifier that predicts labels at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 0.493902439024\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "clf = DummyClassifier(\"uniform\")\n",
    "clf.fit(train_data, train_labels)\n",
    "print(\"Prediction accuracy:\", clf.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the accuracy from chance is about 50%. Let's try a better classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Common Label\n",
    "\n",
    "Scikit learn calls this a \"dummy\" classifier. Easy \"baseline\" for learning. Just labels all the instances with the most common/frequent label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 0.634146341463\n"
     ]
    }
   ],
   "source": [
    "clf = DummyClassifier('most_frequent')\n",
    "clf.fit(train_data, train_labels)\n",
    "print(\"Prediction accuracy:\", clf.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms we have seen in class\n",
    "\n",
    "### SVM\n",
    "\n",
    "The support vector machine is called `LinearSVC` in scikit learn. (SVC stands for Support Vector Classification). You can read more about it [here](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC).\n",
    "\n",
    "First, let us import `LinearSVC` and create the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(random_state=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, let us try setting A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight vector: [[-0.21990599 -1.01692704 -0.10489016 -0.00847219  0.11237232 -0.04511977\n",
      "  -0.04109499]]\n",
      "Bias: [ 1.07079813]\n",
      "\n",
      "Prediction accuracy: 0.786585365854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#train on setting A\n",
    "clf.fit(train_data, train_labels)\n",
    "\n",
    "# Test on setting A\n",
    "print(\"Weight vector: \" + str(clf.coef_))\n",
    "print(\"Bias: \" + str(clf.intercept_))\n",
    "print()\n",
    "print(\"Prediction accuracy:\", clf.score(test_data, test_labels))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us see how well setting B does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight vector: [[ 0.10861834 -0.12546174 -0.33350408  0.32295791 -0.67330538  0.53267674\n",
      "   0.46704266  0.40412243  0.16507542 -0.55770054 -0.64989967 -0.71166451\n",
      "   0.31103794  0.52608218  0.41981271  0.31620929 -0.08838166 -0.65681566\n",
      "  -0.61305185 -0.56524042 -0.23872943 -0.04694518 -0.06467287  0.03388317\n",
      "   0.1363917  -0.48279048 -0.03783187 -0.04204242  0.01826057 -0.22327383\n",
      "  -0.1032918 ]]\n",
      "Bias: [-0.35034748]\n",
      "\n",
      "Prediction accuracy: 0.792682926829\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#train on setting B\n",
    "clf.fit(enc_train_data, enc_train_labels)\n",
    "\n",
    "# Test on setting B\n",
    "print(\"Weight vector: \" + str(clf.coef_))\n",
    "print(\"Bias: \" + str(clf.intercept_))\n",
    "print()\n",
    "print(\"Prediction accuracy:\", clf.score(enc_test_data, enc_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validating SVM\n",
    "\n",
    "We will be cross validating for parameter C. As you might remember from class, 'C' is the penalty parameter of the error formula. \n",
    "\n",
    "[Documentation](http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.01}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.680 (+/-0.030) for {'C': 0.001}\n",
      "0.798 (+/-0.018) for {'C': 0.01}\n",
      "0.798 (+/-0.018) for {'C': 0.01}\n",
      "0.793 (+/-0.027) for {'C': 1}\n",
      "0.792 (+/-0.029) for {'C': 10}\n",
      "0.752 (+/-0.118) for {'C': 100}\n",
      "0.680 (+/-0.193) for {'C': 1000}\n",
      "0.743 (+/-0.077) for {'C': 5000}\n",
      "\n",
      "Weights: [[-0.13076368 -0.75808785 -0.07459106  0.03149947  0.14464803 -0.04700542\n",
      "  -0.03885436]]\n",
      "Bias: [ 0.62738048]\n",
      "\n",
      "Prediction accuracy: 0.786585365854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'C': [1e-3, 1e-2, 1e-2, 1, 10, 100, 1000, 5000]}]\n",
    "\n",
    "print(\"# Tuning hyper-parameters for accuracy\")\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(LinearSVC(), tuned_parameters, cv=5, scoring='accuracy')\n",
    "clf.fit(train_data, train_labels)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "#train and test by using best parameters.\n",
    "clf = LinearSVC(random_state=4000, C=clf.best_params_['C'])\n",
    "clf.fit(train_data, train_labels)\n",
    "\n",
    "print(\"Weights: \" + str(clf.coef_))\n",
    "print(\"Bias: \" + str(clf.intercept_))\n",
    "print()\n",
    "print(\"Prediction accuracy:\", clf.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting A\n",
      "Perceptron weights for setting A: [[ -5. -16.   3.   0.   2.  -1.  -4.]]\n",
      "Perceptron bias for setting A: [ 16.]\n",
      "\n",
      "Prediction accuracy for setting A: 0.746951219512\n",
      "\n",
      "\n",
      "\n",
      "Setting B\n",
      "Perceptron weights for setting B: [[ 3. -1. -3.  2. -3.  2.  2.  4.  1. -3. -2. -5. -1.  3.  2.  3.  0. -3.\n",
      "  -3. -2. -2.  1.  0.  1.  1. -3.  0.  0.  2. -2. -1.]]\n",
      "Perceptron bias for setting B: [-1.]\n",
      "\n",
      "Prediction accuracy: 0.759146341463\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "clf = Perceptron(random_state=2000)\n",
    "\n",
    "#train and test on split A\n",
    "clf.fit(train_data, train_labels)\n",
    "\n",
    "print(\"Setting A\")\n",
    "print(\"Perceptron weights for setting A: \" + str(clf.coef_))\n",
    "print(\"Perceptron bias for setting A: \" + str(clf.intercept_))\n",
    "print()\n",
    "print(\"Prediction accuracy for setting A:\", clf.score(test_data, test_labels))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "#train and test on split B\n",
    "clf.fit(enc_train_data, enc_train_labels)\n",
    "print(\"Setting B\")\n",
    "\n",
    "print(\"Perceptron weights for setting B: \" + str(clf.coef_))\n",
    "print(\"Perceptron bias for setting B: \" + str(clf.intercept_))\n",
    "print()\n",
    "print(\"Prediction accuracy:\", clf.score(enc_test_data, enc_test_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/modules/tree.html\n",
    "#for visualization\n",
    "\n",
    "import graphviz \n",
    "from sklearn import tree\n",
    "\n",
    "#for windows, uncomment the following and replace with path of you local Graphviz.38/bin. Include path of bin and not python lib\n",
    "# os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.795731707317\n",
      "The depth of this tree is 12\n",
      "Accuracy 0.801829268293\n",
      "The depth of this tree is 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'graphs/dt_gini_enc.pdf'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='gini')\n",
    "clf.fit(train_data, train_labels)\n",
    "DecisionTreeClassifier()\n",
    "\n",
    "print(\"Accuracy\", clf.score(test_data, test_labels))\n",
    "print(\"The depth of this tree is\", clf.tree_.max_depth)\n",
    "\n",
    "graph = graphviz.Source(tree.export_graphviz(clf, out_file=None)) \n",
    "graph.render('graphs/dt_gini')\n",
    "\n",
    "clf.fit(enc_train_data, enc_train_labels)\n",
    "DecisionTreeClassifier()\n",
    "\n",
    "print(\"Accuracy\", clf.score(enc_test_data, enc_test_labels))\n",
    "print(\"The depth of this tree is\", clf.tree_.max_depth)\n",
    "\n",
    "\n",
    "graph = graphviz.Source(tree.export_graphviz(clf, out_file=None)) \n",
    "graph.render('graphs/dt_gini_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try using a different criterion to build the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.798780487805\n",
      "The depth of this tree is 12\n",
      "Accuracy 0.80487804878\n",
      "The depth of this tree is 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'graphs/dt_entropy_enc.pdf'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(train_data, train_labels)\n",
    "DecisionTreeClassifier()\n",
    "\n",
    "print(\"Accuracy\", clf.score(test_data, test_labels))\n",
    "print(\"The depth of this tree is\", clf.tree_.max_depth)\n",
    "\n",
    "graph = graphviz.Source(tree.export_graphviz(clf, out_file=None)) \n",
    "graph.render('graphs/dt_entropy')\n",
    "\n",
    "clf.fit(enc_train_data, enc_train_labels)\n",
    "DecisionTreeClassifier()\n",
    "\n",
    "print(\"Accuracy\", clf.score(enc_test_data, enc_test_labels))\n",
    "print(\"The depth of this tree is\", clf.tree_.max_depth)\n",
    "\n",
    "\n",
    "graph = graphviz.Source(tree.export_graphviz(clf, out_file=None)) \n",
    "graph.render('graphs/dt_entropy_enc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try limiting the depth and visualize our tree...\n",
    "\n",
    "http://scikit-learn.org/stable/modules/tree.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.786585365854\n",
      "The depth of this tree is 2\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"504pt\" height=\"258pt\"\n",
       " viewBox=\"0.00 0.00 503.54 258.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 254)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-254 499.5371,-254 499.5371,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"306.8066,-250 187.7306,-250 187.7306,-186 306.8066,-186 306.8066,-250\"/>\n",
       "<text text-anchor=\"middle\" x=\"247.2686\" y=\"-234.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[1] &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"247.2686\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.475</text>\n",
       "<text text-anchor=\"middle\" x=\"247.2686\" y=\"-206.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 981</text>\n",
       "<text text-anchor=\"middle\" x=\"247.2686\" y=\"-192.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [601, 380]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"236.3066,-150 124.2305,-150 124.2305,-86 236.3066,-86 236.3066,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"180.2686\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[0] &lt;= 2.5</text>\n",
       "<text text-anchor=\"middle\" x=\"180.2686\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.392</text>\n",
       "<text text-anchor=\"middle\" x=\"180.2686\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 355</text>\n",
       "<text text-anchor=\"middle\" x=\"180.2686\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [95, 260]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M225.7005,-185.8089C219.9026,-177.1553 213.5562,-167.683 207.494,-158.635\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"210.2701,-156.4903 201.7962,-150.1308 204.4547,-160.3866 210.2701,-156.4903\"/>\n",
       "<text text-anchor=\"middle\" x=\"196.9498\" y=\"-170.4565\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"373.8066,-150 254.7306,-150 254.7306,-86 373.8066,-86 373.8066,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"314.2686\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[0] &lt;= 1.5</text>\n",
       "<text text-anchor=\"middle\" x=\"314.2686\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.31</text>\n",
       "<text text-anchor=\"middle\" x=\"314.2686\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 626</text>\n",
       "<text text-anchor=\"middle\" x=\"314.2686\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [506, 120]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M268.8366,-185.8089C274.6345,-177.1553 280.9809,-167.683 287.0431,-158.635\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"290.0824,-160.3866 292.7409,-150.1308 284.267,-156.4903 290.0824,-160.3866\"/>\n",
       "<text text-anchor=\"middle\" x=\"297.5874\" y=\"-170.4565\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"112.3066,-50 .2305,-50 .2305,0 112.3066,0 112.3066,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"56.2686\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.134</text>\n",
       "<text text-anchor=\"middle\" x=\"56.2686\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 194</text>\n",
       "<text text-anchor=\"middle\" x=\"56.2686\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [14, 180]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M137.5948,-85.9947C124.722,-76.3401 110.6141,-65.7592 97.8157,-56.1604\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"99.7206,-53.2141 89.6206,-50.014 95.5206,-58.8141 99.7206,-53.2141\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"235.8067,-50 130.7304,-50 130.7304,0 235.8067,0 235.8067,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"183.2686\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"183.2686\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 161</text>\n",
       "<text text-anchor=\"middle\" x=\"183.2686\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [81, 80]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M181.301,-85.9947C181.5709,-77.6273 181.8633,-68.5643 182.138,-60.0478\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"185.6373,-60.1217 182.4617,-50.014 178.641,-59.896 185.6373,-60.1217\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"364.8067,-50 259.7304,-50 259.7304,0 364.8067,0 364.8067,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"312.2686\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.443</text>\n",
       "<text text-anchor=\"middle\" x=\"312.2686\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 133</text>\n",
       "<text text-anchor=\"middle\" x=\"312.2686\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [89, 44]</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M313.5803,-85.9947C313.4003,-77.6273 313.2054,-68.5643 313.0223,-60.0478\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"316.5208,-59.9364 312.8065,-50.014 309.5224,-60.087 316.5208,-59.9364\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"495.3066,-50 383.2305,-50 383.2305,0 495.3066,0 495.3066,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"439.2686\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.261</text>\n",
       "<text text-anchor=\"middle\" x=\"439.2686\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 493</text>\n",
       "<text text-anchor=\"middle\" x=\"439.2686\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [417, 76]</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M357.2865,-85.9947C370.2631,-76.3401 384.4847,-65.7592 397.3863,-56.1604\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"399.7137,-58.7913 405.6475,-50.014 395.5353,-53.1751 399.7137,-58.7913\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1a1ae22470>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=2)\n",
    "clf.fit(train_data, train_labels)\n",
    "DecisionTreeClassifier()\n",
    "\n",
    "print(\"Accuracy\", clf.score(test_data, test_labels))\n",
    "print(\"The depth of this tree is\", clf.tree_.max_depth)\n",
    "\n",
    "graph = graphviz.Source(tree.export_graphviz(clf, out_file=None)) \n",
    "graph.render('graphs/dt_gini_limit')\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.786585365854\n",
      "The depth of this tree is 2\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"501pt\" height=\"258pt\"\n",
       " viewBox=\"0.00 0.00 501.04 258.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 254)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-254 497.0371,-254 497.0371,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"307.8066,-250 188.7306,-250 188.7306,-186 307.8066,-186 307.8066,-250\"/>\n",
       "<text text-anchor=\"middle\" x=\"248.2686\" y=\"-234.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[3] &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"248.2686\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.475</text>\n",
       "<text text-anchor=\"middle\" x=\"248.2686\" y=\"-206.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 981</text>\n",
       "<text text-anchor=\"middle\" x=\"248.2686\" y=\"-192.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [601, 380]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"240.8066,-150 121.7306,-150 121.7306,-86 240.8066,-86 240.8066,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"181.2686\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[0] &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"181.2686\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.31</text>\n",
       "<text text-anchor=\"middle\" x=\"181.2686\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 626</text>\n",
       "<text text-anchor=\"middle\" x=\"181.2686\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [506, 120]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M226.7005,-185.8089C220.9026,-177.1553 214.5562,-167.683 208.494,-158.635\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"211.2701,-156.4903 202.7962,-150.1308 205.4547,-160.3866 211.2701,-156.4903\"/>\n",
       "<text text-anchor=\"middle\" x=\"197.9498\" y=\"-170.4565\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"371.3066,-150 259.2305,-150 259.2305,-86 371.3066,-86 371.3066,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"315.2686\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[2] &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"315.2686\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.392</text>\n",
       "<text text-anchor=\"middle\" x=\"315.2686\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 355</text>\n",
       "<text text-anchor=\"middle\" x=\"315.2686\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [95, 260]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M269.8366,-185.8089C275.6345,-177.1553 281.9809,-167.683 288.0431,-158.635\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"291.0824,-160.3866 293.7409,-150.1308 285.267,-156.4903 291.0824,-160.3866\"/>\n",
       "<text text-anchor=\"middle\" x=\"298.5874\" y=\"-170.4565\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"112.3066,-50 .2305,-50 .2305,0 112.3066,0 112.3066,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"56.2686\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.261</text>\n",
       "<text text-anchor=\"middle\" x=\"56.2686\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 493</text>\n",
       "<text text-anchor=\"middle\" x=\"56.2686\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [417, 76]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M138.2506,-85.9947C125.274,-76.3401 111.0524,-65.7592 98.1508,-56.1604\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"100.0018,-53.1751 89.8896,-50.014 95.8234,-58.7913 100.0018,-53.1751\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"235.8067,-50 130.7304,-50 130.7304,0 235.8067,0 235.8067,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"183.2686\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.443</text>\n",
       "<text text-anchor=\"middle\" x=\"183.2686\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 133</text>\n",
       "<text text-anchor=\"middle\" x=\"183.2686\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [89, 44]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M181.9568,-85.9947C182.1368,-77.6273 182.3317,-68.5643 182.5148,-60.0478\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"186.0147,-60.087 182.7306,-50.014 179.0163,-59.9364 186.0147,-60.087\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"369.3066,-50 257.2305,-50 257.2305,0 369.3066,0 369.3066,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"313.2686\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.134</text>\n",
       "<text text-anchor=\"middle\" x=\"313.2686\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 194</text>\n",
       "<text text-anchor=\"middle\" x=\"313.2686\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [14, 180]</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M314.5803,-85.9947C314.4003,-77.6273 314.2054,-68.5643 314.0223,-60.0478\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"317.5208,-59.9364 313.8065,-50.014 310.5224,-60.087 317.5208,-59.9364\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"492.8067,-50 387.7304,-50 387.7304,0 492.8067,0 492.8067,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"440.2686\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"440.2686\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 161</text>\n",
       "<text text-anchor=\"middle\" x=\"440.2686\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [81, 80]</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M358.2865,-85.9947C371.2631,-76.3401 385.4847,-65.7592 398.3863,-56.1604\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"400.7137,-58.7913 406.6475,-50.014 396.5353,-53.1751 400.7137,-58.7913\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1a1ae229b0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf.tree_.__getstate__()\n",
    "clf.fit(enc_train_data, enc_train_labels)\n",
    "DecisionTreeClassifier()\n",
    "\n",
    "print(\"Accuracy\", clf.score(enc_test_data, enc_test_labels))\n",
    "print(\"The depth of this tree is\", clf.tree_.max_depth)\n",
    "\n",
    "graph = graphviz.Source(tree.export_graphviz(clf, out_file=None)) \n",
    "graph.render('graphs/dt_gini_limit_enc')\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Here we'll be training a random forest. Try modifying the parameters and see how it affects the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.15864074  0.50295564  0.07448507  0.07255775  0.04414216  0.06079294\n",
      "  0.08642571]\n",
      "\n",
      "Prediction accuracy: 0.814024390244\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=6, random_state=0, n_estimators=35, criterion='gini')\n",
    "clf.fit(train_data, train_labels)\n",
    "print(clf.feature_importances_)\n",
    "print()\n",
    "print(\"Prediction accuracy:\", clf.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other algorithms\n",
    "\n",
    "- Logistic Regression\n",
    "- Naive Bayes\n",
    "- Adaboost\n",
    "- K Nearest Neighbors\n",
    "- Multiclass classifiers\n",
    "- SVM with Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Try you hands at logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 0.783536585366\n",
      "Prediction Accuracy: 0.792682926829\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "\n",
    "#train and test on setting A\n",
    "clf.fit(train_data, train_labels)\n",
    "print('Prediction Accuracy:', clf.score(test_data, test_labels))\n",
    "\n",
    "#train and test on setting B\n",
    "clf.fit(enc_train_data, enc_train_labels)\n",
    "print('Prediction Accuracy:', clf.score(enc_test_data, enc_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 0.783536585366\n",
      "Prediction Accuracy: 0.801829268293\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(criterion='entropy'), n_estimators=75)\n",
    "\n",
    "#train and test on split A\n",
    "clf.fit(train_data, train_labels)\n",
    "print('Prediction Accuracy:', clf.score(test_data, test_labels))\n",
    "\n",
    "#train and test on split B\n",
    "clf.fit(enc_train_data, enc_train_labels)\n",
    "print('Prediction Accuracy:', clf.score(enc_test_data, enc_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 0.771341463415\n",
      "Prediction Accuracy: 0.774390243902\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "#train and test on split A\n",
    "clf.fit(train_data, train_labels)\n",
    "print('Prediction Accuracy:', clf.score(test_data, test_labels))\n",
    "\n",
    "#train and test on split B\n",
    "clf.fit(enc_train_data, enc_train_labels)\n",
    "print('Prediction Accuracy:', clf.score(enc_test_data, enc_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class classification\n",
    "\n",
    "We come back to iris dataset and use some techniques of multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_train_data, iris_test_data, iris_train_labels, iris_test_labels = train_test_split(iris.data, iris.target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 0.921052631579\n"
     ]
    }
   ],
   "source": [
    "#one-vs-all\n",
    "clf = LinearSVC(random_state=4000, multi_class='ovr')\n",
    "\n",
    "clf.fit(iris_train_data, iris_train_labels)\n",
    "\n",
    "print(\"Prediction accuracy:\", clf.score(iris_test_data, iris_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 0.973684210526\n"
     ]
    }
   ],
   "source": [
    "#one-vs-one\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(random_state=4000)\n",
    "\n",
    "clf.fit(iris_train_data, iris_train_labels)\n",
    "\n",
    "print(\"Prediction accuracy:\", clf.score(iris_test_data, iris_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 0.973684210526\n"
     ]
    }
   ],
   "source": [
    "#multi-class\n",
    "clf = LinearSVC(random_state=4000, multi_class='crammer_singer')\n",
    "\n",
    "clf.fit(iris_train_data, iris_train_labels)\n",
    "\n",
    "print(\"Prediction accuracy:\", clf.score(iris_test_data, iris_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.973684210526\n",
      "The depth of this tree is 4\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"504pt\" height=\"458pt\"\n",
       " viewBox=\"0.00 0.00 503.54 458.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 454)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-454 499.5371,-454 499.5371,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"242.3065,-450 116.2306,-450 116.2306,-386 242.3065,-386 242.3065,-450\"/>\n",
       "<text text-anchor=\"middle\" x=\"179.2686\" y=\"-434.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[2] &lt;= 2.35</text>\n",
       "<text text-anchor=\"middle\" x=\"179.2686\" y=\"-420.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.665</text>\n",
       "<text text-anchor=\"middle\" x=\"179.2686\" y=\"-406.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 112</text>\n",
       "<text text-anchor=\"middle\" x=\"179.2686\" y=\"-392.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [37, 34, 41]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"168.3066,-343 56.2305,-343 56.2305,-293 168.3066,-293 168.3066,-343\"/>\n",
       "<text text-anchor=\"middle\" x=\"112.2686\" y=\"-327.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"112.2686\" y=\"-313.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 37</text>\n",
       "<text text-anchor=\"middle\" x=\"112.2686\" y=\"-299.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [37, 0, 0]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M157.7005,-385.8089C150.3957,-374.9063 142.2203,-362.7041 134.8397,-351.6882\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"137.5967,-349.5151 129.1228,-343.1555 131.7813,-353.4114 137.5967,-349.5151\"/>\n",
       "<text text-anchor=\"middle\" x=\"124.2764\" y=\"-363.4813\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"305.8066,-350 186.7306,-350 186.7306,-286 305.8066,-286 305.8066,-350\"/>\n",
       "<text text-anchor=\"middle\" x=\"246.2686\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[2] &lt;= 4.95</text>\n",
       "<text text-anchor=\"middle\" x=\"246.2686\" y=\"-320.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.496</text>\n",
       "<text text-anchor=\"middle\" x=\"246.2686\" y=\"-306.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 75</text>\n",
       "<text text-anchor=\"middle\" x=\"246.2686\" y=\"-292.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 34, 41]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M200.8366,-385.8089C206.6345,-377.1553 212.9809,-367.683 219.0431,-358.635\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"222.0824,-360.3866 224.7409,-350.1308 216.267,-356.4903 222.0824,-360.3866\"/>\n",
       "<text text-anchor=\"middle\" x=\"229.5874\" y=\"-370.4565\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"237.3066,-250 125.2305,-250 125.2305,-186 237.3066,-186 237.3066,-250\"/>\n",
       "<text text-anchor=\"middle\" x=\"181.2686\" y=\"-234.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[3] &lt;= 1.65</text>\n",
       "<text text-anchor=\"middle\" x=\"181.2686\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.153</text>\n",
       "<text text-anchor=\"middle\" x=\"181.2686\" y=\"-206.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 36</text>\n",
       "<text text-anchor=\"middle\" x=\"181.2686\" y=\"-192.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 33, 3]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M225.3444,-285.8089C219.7195,-277.1553 213.5625,-267.683 207.6813,-258.635\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"210.538,-256.6077 202.1535,-250.1308 204.6689,-260.4227 210.538,-256.6077\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"368.3066,-250 256.2305,-250 256.2305,-186 368.3066,-186 368.3066,-250\"/>\n",
       "<text text-anchor=\"middle\" x=\"312.2686\" y=\"-234.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[2] &lt;= 5.05</text>\n",
       "<text text-anchor=\"middle\" x=\"312.2686\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.05</text>\n",
       "<text text-anchor=\"middle\" x=\"312.2686\" y=\"-206.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 39</text>\n",
       "<text text-anchor=\"middle\" x=\"312.2686\" y=\"-192.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1, 38]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>2&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M267.5147,-285.8089C273.2261,-277.1553 279.4778,-267.683 285.4494,-258.635\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"288.4749,-260.4048 291.0623,-250.1308 282.6326,-256.5489 288.4749,-260.4048\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"112.3066,-143 .2305,-143 .2305,-93 112.3066,-93 112.3066,-143\"/>\n",
       "<text text-anchor=\"middle\" x=\"56.2686\" y=\"-127.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"56.2686\" y=\"-113.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 32</text>\n",
       "<text text-anchor=\"middle\" x=\"56.2686\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 32, 0]</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M141.0297,-185.8089C126.4568,-174.1506 110.0266,-161.0064 95.5382,-149.4157\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"97.7081,-146.6695 87.713,-143.1555 93.3352,-152.1356 97.7081,-146.6695\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"235.8067,-150 130.7304,-150 130.7304,-86 235.8067,-86 235.8067,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"183.2686\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[1] &lt;= 3.1</text>\n",
       "<text text-anchor=\"middle\" x=\"183.2686\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.375</text>\n",
       "<text text-anchor=\"middle\" x=\"183.2686\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n",
       "<text text-anchor=\"middle\" x=\"183.2686\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1, 3]</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>3&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M181.9124,-185.8089C182.0747,-177.6906 182.2515,-168.8517 182.4222,-160.3186\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"185.9252,-160.1988 182.6259,-150.1308 178.9266,-160.0587 185.9252,-160.1988\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"112.8067,-50 7.7304,-50 7.7304,0 112.8067,0 112.8067,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"60.2686\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"60.2686\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n",
       "<text text-anchor=\"middle\" x=\"60.2686\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 3]</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M140.9389,-85.9947C128.1699,-76.3401 114.1758,-65.7592 101.4807,-56.1604\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.4391,-53.2533 93.3516,-50.014 99.2173,-58.837 103.4391,-53.2533\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"236.8067,-50 131.7304,-50 131.7304,0 236.8067,0 236.8067,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.2686\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"184.2686\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n",
       "<text text-anchor=\"middle\" x=\"184.2686\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1, 0]</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M183.6127,-85.9947C183.7027,-77.6273 183.8001,-68.5643 183.8917,-60.0478\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"187.3918,-60.0511 183.9996,-50.014 180.3922,-59.9758 187.3918,-60.0511\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"364.8067,-150 259.7304,-150 259.7304,-86 364.8067,-86 364.8067,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"312.2686\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[1] &lt;= 2.75</text>\n",
       "<text text-anchor=\"middle\" x=\"312.2686\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.375</text>\n",
       "<text text-anchor=\"middle\" x=\"312.2686\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n",
       "<text text-anchor=\"middle\" x=\"312.2686\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1, 3]</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M312.2686,-185.8089C312.2686,-177.6906 312.2686,-168.8517 312.2686,-160.3186\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"315.7687,-160.1307 312.2686,-150.1308 308.7687,-160.1308 315.7687,-160.1307\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"495.3066,-143 383.2305,-143 383.2305,-93 495.3066,-93 495.3066,-143\"/>\n",
       "<text text-anchor=\"middle\" x=\"439.2686\" y=\"-127.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"439.2686\" y=\"-113.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 35</text>\n",
       "<text text-anchor=\"middle\" x=\"439.2686\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 35]</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>8&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M353.1512,-185.8089C367.9573,-174.1506 384.6504,-161.0064 399.3706,-149.4157\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"401.6295,-152.0919 407.321,-143.1555 397.299,-146.5921 401.6295,-152.0919\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"363.8067,-50 258.7304,-50 258.7304,0 363.8067,0 363.8067,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"311.2686\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"311.2686\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n",
       "<text text-anchor=\"middle\" x=\"311.2686\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 3]</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M311.9244,-85.9947C311.8344,-77.6273 311.737,-68.5643 311.6454,-60.0478\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"315.1449,-59.9758 311.5375,-50.014 308.1453,-60.0511 315.1449,-59.9758\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"487.8067,-50 382.7304,-50 382.7304,0 487.8067,0 487.8067,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"435.2686\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"435.2686\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n",
       "<text text-anchor=\"middle\" x=\"435.2686\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1, 0]</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>9&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M354.5982,-85.9947C367.3672,-76.3401 381.3613,-65.7592 394.0564,-56.1604\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"396.3198,-58.837 402.1855,-50.014 392.098,-53.2533 396.3198,-58.837\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1a1adb56a0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(criterion='gini')\n",
    "clf.fit(iris_train_data, iris_train_labels)\n",
    "DecisionTreeClassifier()\n",
    "\n",
    "print(\"Accuracy\", clf.score(iris_test_data, iris_test_labels))\n",
    "print(\"The depth of this tree is\", clf.tree_.max_depth)\n",
    "\n",
    "\n",
    "graph = graphviz.Source(tree.export_graphviz(clf, out_file=None)) \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links!\n",
    "- Scikit learn official page: http://scikit-learn.org/stable/index.html\n",
    "\n",
    "- Pandas official page: http://pandas.pydata.org/pandas-docs/stable/index.html\n",
    "\n",
    "- lots of scikit demos: https://github.com/amueller/scipy-2016-sklearn/tree/master/notebooks\n",
    "\n",
    "- svm documentation: http://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "- decision tree documentation: http://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "- perceptron documentation: http://scikit-learn.org/stable/modules/linear_model.html#perceptron\n",
    "\n",
    "- graphing trees: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\n",
    "\n",
    "- cross-validation parameter search documentation: http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "- Parts of this tutorial have been based on this tutorial: https://github.com/amueller/scipy-2016-sklearn/blob/master/notebooks/10%20Case%20Study%20-%20Titanic%20Survival.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
